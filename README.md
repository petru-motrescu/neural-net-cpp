# About neural-net

My first attempts at building a neural network from scratch.


# Study notes

- In a NN that recognizes digits, we have 1 neuron for each pixel (width * height) and 10 output neurons, one for each digit.
- Sigmoid was used initially in ML to squash the sum of a neuron's inputs into the 0..1 interval.
- ReLU has replaced sigmoid as it is faster to train.


# TODO

- Biases
- Replace sigmoid with relu


# Thanks

Thanks to the authors of the following articles:

- https://en.wikipedia.org/wiki/Backpropagation
- https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/
- http://stevenmiller888.github.io/mind-how-to-build-a-neural-network/
- https://youtu.be/aircAruvnKk
